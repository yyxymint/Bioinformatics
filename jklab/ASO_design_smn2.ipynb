{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selected-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pkg_resources import resource_filename\n",
    "from utils2 import one_hot_encode\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import average_precision_score\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-negotiation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decent-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ('snp_data/spliceai{}.h5'.format(x) for x in [1,2,3,4,5])\n",
    "spliceai_models=[load_model(resource_filename('spliceai', x),compile=False) for x in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-christianity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_seq(seq_len):\n",
    "    \n",
    "    random_seq=''\n",
    "    for _ in range(seq_len):\n",
    "        xx=random.random()\n",
    "        \n",
    "        if xx<0.25:\n",
    "            random_seq+='A'\n",
    "        elif xx<0.5:\n",
    "            random_seq+='T'\n",
    "        elif xx<0.75:\n",
    "            random_seq+='G'\n",
    "        else:\n",
    "            random_seq+='C'\n",
    "    \n",
    "    return random_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-canyon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-rental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "annoying-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_context='AGATTTGATTAAAAGGGTCTTTAGAGCTGATGTCAGGTGTATGATGCCTTTAAGAGCAGTTTTTATAGTGCAGGGGGTGGTCAAAAGAGAAAATAGGTGCTTTCTGAGGTGACGGAGCCTTGAGACTAGCTTATAGTAGTAACTGGGTTATGTCGTGACTTTTATTCTGTGCACCACCCTGTAACATGTACATTTTTATTCCTATTTTCGTAGCATGCTCTAAAGAATGGTGACATTTGTGAAACTTCGGGTAAACCAAAAACCACACCTAAAAGAAAACCTGCTAAGAAGAATAAAAGCCAAAAGAAGAATACTGCAGCTTCCTTACAACAGGTTATTTTAAAATGTTGAGATTTAACTTCAAAGGATGTCTCATTAGTCCTTATTTAATAGTGTAAAATGTCTTTAACTTAAGTGATTAgtacagtgtttctattgacatatacttatacaacttcaaaaacaactattaaattttctgttatttaggaacatgcatattagtcatgaaagtataaagaattagatgggaatgataaatgctaaaatcaggacatgtgttccatttgtgaatggaaggcagggagaaggtgccgtttggaaggagtacccaagagccgtaagctgaattggcagtgttttacatcttaagctgagagatagatttttttttcccctttttctttaaaAACTCTAAAACTGTTAATTCCAAGGAACCCAGAAGTCTAGGTAGATTATTTCTGCTAGTTAAAAGCAGTAGTCCTGAAAGCTGAATATTTTGGTGTCTTTTGAGCCAACTTTAGTTTCATCATTACCAAGGGGGaagagagctaacagttgatgagcacttgctctaggccagtccagagtgctgggcaccatacgcattttatctccctcccgctattcacaacaaatatgggaggtagtttatattatagccatctaataagatggggaaactaagactcaaagagattcagaaacttgtccatgattataaatgtaagagagttggaattcagatttatgtatttagaccccaagcctttctcattacatcattttgccTTCCAAATCTCTACCCTCTATCCTTCACCTCCCCACTGATCAAAACGAGATGATAGTTTGCCCTCTTCAAAAGAAATGTGTGCATGTATATATCTTTGATTTCTTTTGTAGTGGAAAGTTGGGGACAAATGTTCTGCCATTTGGTCAGAAGACGGTTGCATTTACCCAGCTACCATTGCTTCAATTGATTTTAAGAGAGAAACCTGTGTTGTGGTTTACACTGGATATGGAAATAGAGAGGAGCAAAATCTGTCCGATCTACTTTCCCCAATCTGTGAAGTAGCTAATAATATAGAACAAAATGCTCAAGAGGTAAGGATACaaaaaaaaaaaaaTTCAATTTCTGGAAGCAGAGACTAGATGAGAAACTGTTAAACAGTATACACAGTTGTCAGTTTGATCCACCGAGGCATTAATTTTTTCTTAATCACACCCTTATAACAAAAACCTGCATATTTTTTCTTTTTAAAGAATGAAAATGAAAGCCAAGTTTCAACAGATGAAAGTGAGAACTCCAGGTCTCCTGGAAATAAATCAGATAACATCAAGCCCAAATCTGCTCCATGGAACTCTTTTCTCCCTCCACCACCCCCCATGCCAGGGCCAAGACTGGGACCAGGAAAGGTAAACCTTCTATGAAAGTTTTCCAGAAAATAGTTAATGTCGGGACATTTAACCTCTCTGTTAACTAATTTGTAGCTCTCCCATGAAACTTTTGTAGCTTAAATACACAAGAATTTTTTGAAAAGGAAATAAGATAATGATGCAAAATAGTTAATTTTTTAAAAAAATGTTAGACACTGCAGTGGATGCAACAAAATACTTTATATGAAAGATTTATCCAGTTAACTTTTGTGGAGTATTAGGTATTAGACTAATAATTAGCACACTTACTTAAGTTAGAAAGTATAATAATGCgccggacgcggtagctcacgcctgtaatcccagcactttgggaggccaaggtgggcggatcacaaggtcaggagatcgagaccatcctggctaacacggtgaaaccccatctctactgaaaatacaaaaaaatttgccgggcgtgatggcgggcacctgtagtcccagctactcgggaggctgaggcaggaggatggtgtgaaccccggaggcagagcttgcagtgagtcaagatcgtgccactgcactccaacctgggcgacagaatgagactccatctcaaacaaaaaaacaaaacaaaacaaaaaaaaGTGTAATAATAATTTATCATTAGCTGGATGATATGCTGTTGTTTCCCATGTCACCTGTATAAGATATGTAAAATAAGAACACATTATTTACATCTAATATAGATAAAATCCTGAGGCGCTCTCAGATTGTTTTGTAGAGTTCAAATGTAAATATTGTTTTCATTTATGGTCCTTTTGGTTATAAGTAACAGAAATCAACTCTAAAAAGATTTTTATTATAGGTTAGATTATGTCATGGAACCTTAAGGCTTGTCCCTTTCTAGTTCTTTTGTGTAAAGCGGTGATTTCTTCCATGGAGGGAATGGTATTTAGGCAAtttttttttttttttcgagatggagtcttgctctgtcgctcaggctggagtgcagtggcaccatttcagctcactgcaacttccacctcctgggttcaagtgattctcctgcttcagcctcccaagtagctgagattacaggcacccgccaccacacccggcttattttgtatttttagtagagatggggtttcaccatgttggccaggctggtcttgaactcctgacctcaagtgatctccccaccttggccttccaaagtgctaggattacaggcgCCTAGCCTAGGCAGTCATTTTCAAAAAACAAGCATGACTCACCAAAAGTTTTAAGATTTTCTGTGATAATGTTCTTATTGAGGCTTACATTATATTACAGTTTCTTGAATCTAAAATGATGTACCCTCTTAGAATATATACATCATGCTTCATTGGTCTCAGGGGGCTGATTTTTATAAGGAGAGATTTGCTAGTTTTCACAATATGTCCTCTAAGTTGGCATGTATAGCTAAACAGGCTTTCATAAAAATATACAATTTAGTTAATGAAATTTGGGATATAGTCTTTTATGATTGAAATAATTTTGCTAAATAGACTGTCTCTGATTTATTAGGTAATCACCACTCTTATTTTGTTTTACTTCCTTAATGTCTACATAGAAAGGAAATGAGAAAAATCCAGAGGTTGTCATTTGACTTATGAGTCTGTTTGACTTCAGGATTTGGTACATGAAATTTCACTTAATCTTTTTGATATGTATAAAACAAATATTCTGGGTAATTATTTTTATCCTTTTGGTTTTGAGTCCTTTTTATTCCTATCATATTGAAATTGGTAAGTTAATTTTCCTTTGAAATATTCCTTATAGCCAGGTCTAAAATTCAATGgcccaccaccgccaccgccaccaccaccaccccacTTACTATCATGCTGGCTGCCTCCATTTCCTTCTGGACCACCAGTAAGTAAAAAAGAGTATAGGTTAGATTTTGCTTTCACATACAATTTGATAATTAGCAGAATAGAGGATTGTAAAATGTCATTGTAGAACATCCCTTGGGCCAGATTCTAATGGGTAGAAATTTGAACTAAACCTCTGGGTTTTGTTTGTTTTTAATGCCTTTCTGTTACCCAGATGCAGTGCTCTTGTAGTCCCAAGTCTAAGCTCTAGGTTGCCTTCTTTCCTGGCAGAAGTTGGTGTCTATGCCATAAGGAGGTAGTTCCTGTTAGAAGGGATTTAATTATACCTTATATAAGGAATTAGTGTTTGCCCTTCTAGGTATAGTTGGATGTTAGCTTCTGATGTAAACTGGAtttctttttctttctctctctttttttttttttgttttggaggcagagttttgcccttgtaccccaggctggagtgcagtggtgtgatctcagctcacagcaacctccgcctcctgggttcaagcaattctgcctcggcctcccaagtagctgggattacaggcgactgccaccacacccggctaatttttgttttattagtagagatggggtttcaccatgttggccagactgatcttgaactcctgacctcaggtgatccacccgccttggcctcccaaagcgctgggattacaggcgtgagctgccgcacccagcTGTAAACTGGATTTCTAATGGTAGATTTTTAGGTATTAACAATAGATAAAAAGATACTTTTTGGCATACTGTGTATTGGGATGGGGTTAGAACAGGTGTTCTACCCAAGACATTTACTTAAAATCGCCCTCGAAATGCTATGTGAGCtgtgtgtgtgtgtgtgtgtgtgtgtgtATTAAGGAAAAGCATGAAAGTATTTATGCTTGAttttttttttttACTCATAGCTTCATAGTGGAACAGATACATAGTCTAAATCAAAATGTTTAAACTTTTTATGTCACTTGCTGTCTTTTCGTCCTCGTTAAATTTAATTTTGTTGGTCTTTTGTTGTTATTGGTTGGTTTTCTCCAAATGCTAGCTATGTTAAGAAATTTAAggccaggtacagtggctcatgcctgtaatcccggcattttagaaggctgaggcaggaggatcacttgagctcaggagtttgagaccagtctgggcaacatagcaagacctcgtctttgtttaggggaaaaaaaagaaaTTTAAGTAGGAGATTATATAAGCAAAAATACAATTAATTTCCAGCATTCACTATATAATATAAATCTCCAGACTTTACTTTTTTGTTTACTGGATATAAACAATATCTTTTTCTGTCTCCAGATAATTCCCCCACCACCTCCCATATGTCCAGATTCTCTTGATGATGCTGATGCTTTGGGAAGTATGTTAATTTCATGGTACATGAGTGGCTATCATACTGGCTATTATATG'.upper()\n",
    "right_context='gaaatgctggcatagagcagcactaaatgacaccactaaagaaacgatcagacagatctggaatgtgaagcgttatagaagataactggcctcatttcttcaaaatatcaagtgttgggaaagaaaaaaggaagtggaatgggtaactcttcttgattaaaagttatgtaataaccaaatgcaatgtgaaatattttactggactctattttgaaaaaccatctgtaaaagactgaggtgggggtgggaggccagcacggtggtgaggcagttgagaaaatttgaatgtggattagattttgaatgatattggataattattggtaattttatgagctgtgagaagggtgttgtagtttataaaagactgtcttaatttgcatacttaagcatttaggaatgaagtgttagagtgtcttaaaatgtttcaaatggtttaacaaaatgtatgtgaggcgtatgtggcaaaatgttacagaatctaactggtggacatggctgttcattgtactgtttttttctatcttctatatgtttaaaagtatataataaaaaTATTTAAtttttttttAAATTAGCTGTATCTGTGATTGTATTTCTTTTTTGCATATTATTTTGCCCTTTGGCCCATATTTTGATATGGATGCCACCATAGCATTTTGTGTATGTGCATGTGTATTCCCACTTAATGTCACATTTTTCATGTCTTTACATAttcttatttttgtttgtttttgagacagagtctcgctctgctgcccacgctggagtgcagtggtgcaatctcagctcactgcaacctctgctatccgggttcaagcagttctcgtgcctcacccacgtgagtagttgggattacaggcatgtggcaccatgccccactaagttttgtatttttagtagagatggagtttcaccatgttggccaggctggtctcaaactcctgccctcaagtgattcgaccaccctggcctcccaaagtgctgggattacagccgtgagccaccgcacacggccTCTCTATTTATTTCTATACATAGCTTTTCACATTATATTATGTTTATATATTGTTTATATCTGTATTTCCTCTTTCATTAGAGAAAAGGTAGTACATCTTATTCTTCATGGTGTCTACAATATCTGGCAGTTTTTGGAAGTCAAGCGTGAGCTTAGAGCATAGACTGGTGGGATTGTCAAAGAAGAGGGCAACTGGAAGAGAACTGTCAGTTATTTTTGGATCAGTCTTTAATTCATCATGACGGGTTAGGCATTAGTTGTATTTCTTGCTAATTTTGAAGAAGACTTATTAACAAATCCTACATTAGGTAAATGGTTTTGAAAGTTGAGTTAATCATAATGGTGTTTGACCTAGGACTATTTTTAGGCCCTATTTATCTTAATATCGAATAATGAAGCAGCTTCCCCCTTAGATATAGACAGAAAACATCAAAGCCACCACACTACCTGGCTGGATTTATCCTAGTAATAAAATCAAAACTGAGCTAGTTCTCTGGCTTTCATTGTAATAATTGTCCTTGTGGTTGTAAGGAATCTAGATGAAAATTACATGGTCTGTTCTACAGCCACAGCTGTACCTACATTCAGAAGACAGACAAAAGTTGCTGTGTTTGAAGAGATCCTTCATTAAGGGATCAGACAGAGATTACTTTGAGACATATTCTAAGTTTAACTTTTCTGCAGGGTTGCCATTAACAGAAATAAACTACAGAGTTAAtttctttttgtttttgatacagtctaactctcacccaagctggagtgcagtggcgcaatttcagctcactgcaacctctgcctcccaggttcaagcaattctcctgcctcagcctcccgagcagctgggactacaggcatgtgccactatgcctggctaatttttgtatttttagtagtagagacgtggtttcgccacgttggccaggctggtctggaactcctgaccccaggtaatccacctgcctcggcctcccaaagtgctgggattacaagcttgagccactacgcctgaccCAGAGTTAACTTTTTAAAAAAGTTTTTATGAACTTAAGTCTTGTGATGTTTGAAATAATGGATTCAATTTAGACATCAAATTCCAGAAGTTACTAAGAGCAgctgggcgcggcagctcacacctgtaatcccagcactttgggaggccgaggcgggtggatcacctgagatcaggagttccagaccagcctggccaacatagtaaaaccctgtctctactaaaaatacaaaaattagcccggcatggtggcacgccctgtagtcccagctacttgggaggctgaggcaggagaattgcttgaacccgggaggtggaggttgtggtgagccgagattgtgccactgtactcaagcctgggctaaaaagcgagactccgtctcaaaaaaaaaaaaaaaaaaaaCACGTTACTAAGAGCAACTCTGggccaggcacggtggcttacacctgtaatcccagcattttgggaggacgagacaggcggatcacttgagcccaggagttcaagaccagcataagcaacaacgcaaaacccctgactctacaaaacatgaaagaattagcaaggcatggtggtgcatgcctgtagtcccagctactggagaggctgaggcaaaaggatcacttgagtacaggaggttgaggctgtgtaatgagccgtgttcacaccattgcacttcagcctgggcaacagactgagaccctgtctcaaaaaaaaaaaccaaaccaaagcaacaaacaaaaaaCAAGAGCAACTCTGCTTCTGTACACttttttttttttttttggtagtgacatgatctatgttgcccaagctggtctcgagttcctgggttcaagccattctcccacctcgggctcccaaagtgctaggattacaggcatgaatcaccatgcccagccCTTCTGTACACTTTTCACAGTGTACCCTTTTGTGTTTTTTAAAATGTTTGTGTATACATTTATTGTGAATTTTTAAAAAACATGTAATTAAggccaggcatggtggctcatacctgtaatcctagcactttgagaggctgaggtgggtggatcacctgaggtcggtagttcgagaccagcctggcccaacatggtgaaaccccatctctactaaaaatacaaaaaaaaaattagctcggcatggtggtgggcgcctgtgatcccagctactggagaggctgaagcatgagaatcacttgaacccaggaggcggaggttgcagtgagccaagatcgtgccactacactccagcctgggtgactcagtgactgtctcaaaaagaaaaaaaGTAATTAAGTTCTGTCATGATATATCATCATTACCCTTTTTGAACTTTTAAAATTTTTTATCTTTAGAGGTAATTCATATAATGTTCTTCAATAGATAAGTGCTTTTCTGTcaatatatcttggagaacacaccatatcagtatttaaaactctcattcttcctatttctccacatcctctccagcacccgttgtttcctgactttttaatgattgccattctaactggtgtgagatggtatcttattgtggttttgatttgcatttctctgatggccagtgatggtgagcattttttcatgtgttttttagctgcataaatgtcttcttttgagaagtgtctgttcatgtccttcgcccactttttgatggggttgtctgtttttttcttgtaaatttgtttgagttcattgtagattctggatattagccctttgtcagatgagtagattgcaaaaattttctcccattttgtaggttgcctgttcactctgatggtagtttcttttgctgtgcagaagctctttagtttaattagatcccagttttggcttttgttgccgttgcttttggtgttttagacatgaagtccttgcccatgcctatgtcctgaatggtaatgcctaggttttcttctagggtttttatggttttaggtctaacatttaagtctttaatccatcttgaattaatttttgtataaggtgtaaggaagggatccagtttcagctttctacatatggctagccagtttcccagcaccatttattaaatagggaatcctttccccattgcttgtttttctcaggtttgtcaaagatcagatagttgtagatatgcggcgttatttctgagggctctgttctgttccattggtctatatctctgttttggtaccagtaccatgctgttttggttactgtagccttgtagtatagtttgaagtcaggtagcgtgatgcctccagctttgttcttttggcttaggattgacttggcgatgcgggctcttttttggttccatatgaactttaaagtagttttttccaattctgtgaagaaagtcattggtagcttgatggggatggcattgaatctgtaaattaccttgggcagtatggccattttcacgatattgattcttcctacccatgagcatggaatgttcttccatttgtttgtatcctcttttatttcattgagcagtggtttgtagttctccttgaagaggtccttcacatcccttgtaagttggattcctaggtattttattctctttgaagcaattgtgaatgggagttcactcatgatttggctctctgtttgtctgttattgctgtataagaatgcttgtgatttttgtacattgattttgtatcctgagactttgctgaagttgcttatcagcttaaggagattttgggctgagacaatggggttttctagatatacaatcatgtaatctgcaaacagggacaatttggcttcctcttttcctaattgaatacccgttatttctttctcctgcctaattgccctggccagaacttccaacactatgttgaataggagtggtgagagagggcatccctgtcttgtgcgtgttttcaaagggaatgcttccagtttttgcccattcagtatgatattggctgtgggtttgtcatagatagctcttat'.upper()\n",
    "intron_exon_intron = 'GTAAGTAATCACTCAGCATCTTTTCCTGACAATTTTTTTGTAGTTATGTGACTTTGTTTTGTAAATTTATAAAATACTACTTGCTTCTCTCTTTATATTACTaaaaaataaaaataaaaaaaTACAACTGTCTGAGGCTTAAATTACTCTTGCATTGTCCCTAAGTATAATTTTAGTTAATTTTAAAAAGCTTTCATGCTATTGTTAGATTATTTTGATTATACACTTTTGAATTGAAATTATACTTTTTCTAAATAATGTTTTAATCTCTGATTTGAAATTGATTGTAGGGAATGGAAAAGATGGGATAATTTTTCATAAATGAAAAATGAAAttcttttttttttttttttttttttgagacggagtcttgctctgttgcccaggctggagtgcaatggcgtgatcttggctcacagcaagctctgcctcctggattcacgccattctcctgcctcagcctcagaggtagctgggactacaggtgcctgccaccacgcctgtctaattttttgtatttttttgtaaagacagggtttcactgtgttagccaggatggtctcaatctcctgaccccgtgatccacccgcctcggccttccaaGAGAAATGAAATTTTTTTAATGCACAAAGATCTGGGGTAATGTGTACCACATTGAACCTTGGGGAGTATGGCTTCAAACTTGTCACTTTATACGTTAGTCTCCTACGGACATGTTCTATTGTATTTTAGTCAGAACATTTAAAattattttattttattttattttttttttttttttgagacggagtctcgctctgtcacccaggctggagtacagtggcgcagtctcggctcactgcaagctccgcctcccgggttcacgccattctcctgcctcagcctctccgagtagctgggactacaggcgcccgccaccacgcccggctaatttttttttatttttagtagagacggggtttcaccgtggtctcgatctcctgacctcgtgatccacccgcctcggcctcccaaagtgctgggattacaagcgtgagccaccgcgcccggccTAAAATTATTTTTAAAAGTAAGCTCTTGTGCCCTGCTAAAATTATGATGTGATATTGTAGGCACTTGTATTTTTAGTAAATTAATATAGAAGAAACAACTGACTTAAAGGTGTATGTTTTTAAATGTATCATCTGTGTGTGCCCCCATTAATATTCTTATTTAAAAGTTAAggccagacatggtggcttacaactgtaatcccaacagtttgtgaggccgaggcaggcagatcacttgaggtcaggagtttgagaccagcctggccaacatgatgaaaccttgtctctactaaaaataccaaaaaaaatttagccaggcatggtggcacatgcctgtaatccgagctacttgggaggctgtggcaggaaaattgctttaatctgggaggcagaggttgcagtgagttgagattgtgccactgcactccacccttggtgacagagtgagattccatctcaaaaaaagaaaaaggcctggcacggtggctcacacctataatcccagtactttgggaggtagaggcaggtggatcacttgaggttaggagttcaggaccagcctggccaacatggtgactactccatttctactaaatacacaaaacttagcccagtggcgggcagttgtaatcccagctacttgagaggttgaggcaggagaatcacttgaacctgggaggcagaggttgcagtgagccgagatcacaccgctgcactctagcctggccaacagagtgagaATTTGCGGAGGGaaaaaaaaGTCACGCTTCAGTTGTTGTAGTATAACCTTGGTATATTGTATGTATCATGAATTCCTCATTTTAATGACCAAAAAGTAATAAATCAACAGCTTGTAATTTGTTTTGAGATCAGTTATCTGACTGTAACACTGTAGGCTTTTGTGTTTTTTAAATTATGAAATATTTGAAAAAAATACATAATGTATATATAAAGTATTGGTATAATTTATGttctaaataactttcttgagaaataattcacatggtgtgcagtttacctttgaaagtatacaagttggctgggcacaatggctcacgcctgtaatcccagcactttgggaggccagggcaggtggatcacgaggtcaggagatcgagaccatcctggctaacatggtgaaaccccgtctctactaaaagtacaaaaacaaattagccgggcatgttggcgggcaccttttgtcccagctgctcgggaggctgaggcaggagagtggcgtgaacccaggaggtggagcttgcagtgagccgagattgtgccagtgcactccagcctgggcgacagagcgagactctgtctcaaaaaataaaataaaaaagaaagtatacaagtcagtggttttggttttcagttatgcaaccatcactacaatttaagaacattttcatcaccccaaaaagaaaccctgttaccttcattttccccagccctaggcagtcagtacactttctgtctctatgaatttgtctattttagatattatatataaacggaattatacgatatgtggtcttttgtgtctggcttctttcacttagcatgctattttcaagattcatccatgctgtagaatgcaccagtactgcattccttcttattgctgaatattctgttgtttggttatatcacattttatccattcatcagttcatggacatttaggttgtttttatttttgggctataatgaataatgttgctatgaacattcgtttgtgttctttttgtttttttggttttttgggttttttttgttttgtttttgtttttgagacagtcttgctctgtctcctaagctggagtgcagtggcatgatcttggcttactgcaagctctgcctcccgggttcacaccattctcctgcctcagcccgacaagtagctgggactacaggcgtgtgccaccatgcacggctaattttttgtatttttagtagagatggggtttcaccgtgttagccaggatggtctcgatctcctgacctcgtgatctgcctgcctaggcctcccaaagtgctgggattacaggcgtgagccactgcacctggccTTAAGTGTTTTTAATACGTCATTGCCTTAAGCTAACAATTCTTAACCTTTGTTCTACTGAAGCCACGTGGTTGAGATAGGCTCTGAGTCTAGCTTTTAACCTCTATCTTTTTGTCTTAGAAATCTAAGCAGAATGCAAATGACTAAGAATAATGTTGTTGAAATAACATAAAATAGGTTATAACTTTGATACTCATTAGTAACAAATCTTTCAATACATCTTACGGTCTGTTAGGTGTAGATTAGTAATGAAGTGGGAAGCCACTGCAAGCTAGTATACATGTAGGGAAAGATAGAAAGCATTGAAGCCAGAAGAGAGACAGAGGACATTTGGGCTAGATCTGACAAGAAAAACAAATGttttagtattaatttttgactttaaattttttttttATTTAGTGAATACTGGTGTTTAATGGTCTCATTTTAATAAGTATGACACAGGTAGTTTAAGGTCATATATTTTATTTGATGAAAATAAGGTATAggccgggcacggtggctcacacctgtaatcccagcactttgggaggccgaggcaggcggatcacctgaggtcgggagttagagactagcctcaacatggagaaaccccgtctctactaaaaaaaatacaaaattaggcgggcgtggtggtgcatgcctgtaatcccagctactcaggaggctgaggcaggagaattgcttgaacctgggaggtggaggttgcggtgagccgagatcacctcattgcactccagcctgggcaacaagagcaaaactccatctcaaaaaaaaaaaaaTAAGGTATAAGCGGGCTCAGGAACATCATTGGACATACTGAAAGAAGAAAAATCAgctgggcgcagtggctcacgccggtaatcccaacactttgggaggccaaggcaggcgaatcacctgaagtcgggagttccagatcagcctgaccaacatggagaaaccctgtctctactaaaaatacaaaactagccgggcatggtggcgcatgcctgtaatcccagctacttgggaggctgaggcaggagaattgcttgaaccgagaaggcggaggttgcggtgagccaagattgcaccattgcactccagcctgggcaacaagagcgaaactccgtctcaaaaaaaaaaggaagaaaaaTatttttttaaattaattagtttatttattttttaagatggagttttgccctgtcacccaggctggggtgcaatggtgcaatctcggctcactgcaacctccgcctcctgggttcaagtgattctcctgcctcagcttcccgagtagctgtgattacagccatatgccaccacgcccagccagttttgtgttttgttttgttttttgttttttttttttgagagggtgtcttgctctgtcccccaagctggagtgcagcggcgcgatcttggctcactgcaagctctgcctcccaggttcacaccattctcttgcctcagcctcccgagtagctgggactacaggtgcccgccaccacacccggctaatttttttgtgtttttagtagagatggggtttcactgtgttagccaggatggtctcgatctcctgaccttttgatccacccgcctcagcctccccaagtgctgggattataggcgtgagccactgtgcccggcctagtcttgtatttttagtagagtcgggatttctccatgttggtcaggctgttctccaaatccgacctcaggtgatccgcccgccttggcctccaaaagtgcaaggcaaggcattacaggcatgagccactgtgaccggcAATGtttttaaattttttacatttaaattttattttttagagaccaggtctcactctattgctcaggctggagtgcaagggcacattcacagctcactgcagccttgacctccagggctcaagcagtcctctcacctcagtttcccgagtagctgggactacagtgataatgccactgcacctggctaatttttatttttatttatttatttttttttgagacagagtcttgctctgtcacccaggctggagtgcagtggtgtaaatctcagctcactgcagcctccgcctcctgggttcaagtgattctcctgcctcaacctcccaagtagctgggattagaggtccccaccaccatgcctggctaattttttgtactttcagtagaaacggggttttgccatgttggccaggctgttctcgaactcctgagctcaggtgatccaactgtctcggcctcccaaagtgctgggattacaggcgtgagccactgtgcctagcctgagccaccacgccggcctaatttttaaattttttgtagagacagggtctcattatgttgcccagggtggtgtcaagctccaggtctcaagtgatccccctacctccgcctcccaaagttgtgggattgtaggcatgagccactgcAAGAAAACCTTAACTGCAGCCTAATAATTGTTTTCTTTGGGATAACTTTTAAAGTACATTAAAAGACTATCAACTTAATTTCTGATCATATTTTGTTGAATAAAATAAGTAAAATGTCTTGTGAAACAAAATGCTTTTTAACatccatataaagctatctatatatagctatctatatctatatagctattttttttAACTTCCTTTATTTTCCTTACAGGGTTTTAGACAAAATCAAAAAGAAGGAAGGTGCTCACATTCCTTAAATTAAGGAGTAAGTCTGCCAGCATTATGAAAGTGAATCTTACTTTTGTAAAACTTTATGGTTTGTGGAAAACAAATGTTTTTGAACATTTAAAAAGTTCAGATGTTAGAAAGTTGAAAGGTTAATGTAAAACAATCAATATTAAAGAATTTTGATGCCAAAACTATTAGATAAAAGGTTAATCTACATCCCTACTAGAATTCTCATACTTAACTGGTTGGTTGTGTGGAAGAAACATACTTTCACAATAAAGAGCTTTAGGATATGATGCCATTTTATATCACTAGTAGGCAGACCAGCAGACttttttttATTGTGATATGGGATAACCTAGGCATACTGCACTGTACACTCTGACATATGAAGTGCTCTAGTCAAGTTTAACTGGTGTCCACAGAGGACATGGTTTaactggaattcgtcaagcctctggttctaatttctcatttgcag'.upper()\n",
    "\n",
    "full_seq = left_context + intron_exon_intron + right_context\n",
    "\n",
    "exon_seq = 'GGTTTTAGACAAAATCAAAAAGAAGGAAGGTGCTCACATTCCTTAAATTAAGGA'\n",
    "ASO_seq = 'CCAGCATTATGAAAGTG'\n",
    "\n",
    "\n",
    "acceptor_pos=10769 # full_seq에서 acceptor 위치\n",
    "donor_pos=10822 # (10769 + len(exon_seq)-1), full_seq에서 donor 위치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "center-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AG'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq[acceptor_pos-2:acceptor_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "biblical-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GT'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq[donor_pos+1:donor_pos+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adult-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16267"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-armenia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spoken-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_with_seq(seq):\n",
    "    input_x = one_hot_encode(seq)[None, :]\n",
    "    output_y = np.mean([spliceai_models[m].predict(input_x) for m in range(5)], axis=0)\n",
    "    return output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hollywood-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_given_ASO(input_seq, donor_pos, acceptor_pos, ASO_seq):\n",
    "    original_seq = input_seq\n",
    "    masked_seq = input_seq[:input_seq.find(ASO_seq)] + 'N'*17 + input_seq[input_seq.find(ASO_seq)+17:]\n",
    "    \n",
    "    print(original_seq[10832-20:10832+40])\n",
    "    print(masked_seq[10832-20:10832+40])\n",
    "                                  \n",
    "    original_donor_seq = original_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    original_acceptor_seq = original_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    masked_donor_seq = masked_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    masked_acceptor_seq = masked_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    original_donor_prob = get_prob_with_seq(original_donor_seq)[0][0][2]\n",
    "    original_acceptor_prob = get_prob_with_seq(original_acceptor_seq)[0][0][1]\n",
    "\n",
    "    masked_donor_prob = get_prob_with_seq(masked_donor_seq)[0][0][2]\n",
    "    masked_acceptor_prob = get_prob_with_seq(masked_acceptor_seq)[0][0][1]\n",
    "\n",
    "    \n",
    "    print('original acceptor prob : ',original_acceptor_prob)\n",
    "    print('original donor prob : ',original_donor_prob)\n",
    "    \n",
    "    print('masked acceptor prob : ',masked_acceptor_prob)\n",
    "    print('masked donor prob : ',masked_donor_prob)\n",
    "    \n",
    "#     print(masked_donor_prob-original_donor_prob, masked_acceptor_prob-original_acceptor_prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "utility-postage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAAATTAAGGAGTAAGTCTGCCAGCATTATGAAAGTGAATCTTACTTTTGTAAAACTTTA\n",
      "TAAATTAAGGAGTAAGTCTGNNNNNNNNNNNNNNNNNAATCTTACTTTTGTAAAACTTTA\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced8779280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "original acceptor prob :  0.7941215\n",
      "original donor prob :  0.8757514\n",
      "masked acceptor prob :  0.9725332\n",
      "masked donor prob :  0.98298824\n"
     ]
    }
   ],
   "source": [
    "predict_given_ASO(full_seq,donor_pos,acceptor_pos,ASO_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resistant-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5769, 5822)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptor_pos-5000,donor_pos-5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chicken-olympus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 5760  /  done 5780  /  done 5800  /  done 5820  /  done 5840  /  done 5860  /  done 5880  /  done 5900  /  done 5920  /  done 5940  /  done 5960  /  done 5980  /  done 6000  /  done 6020  /  done 6040  /  done 6060  /  done 6080  /  done 6100  /  done 6120  /  done 6140  /  done 6160  /  done 6180  /  done 6200  /  done 6220  /  done 6240  /  done 6260  /  done 6280  /  done 6300  /  done 6320  /  done 6340  /  done 6360  /  done 6380  /  done 6400  /  done 6420  /  done 6440  /  done 6460  /  done 6480  /  done 6500  /  done 6560  /  done 6580  /  done 6600  /  done 6620  /  done 6640  /  done 6660  /  done 6680  /  done 6700  /  done 6720  /  done 6740  /  done 6760  /  done 6780  /  done 6800  /  done 6820  /  done 6840  /  done 6860  /  done 6880  /  done 6900  /  done 6920  /  done 6940  /  done 6960  /  done 6980  /  done 7000  /  done 7020  /  done 7040  /  done 7060  /  done 7080  /  done 7100  /  done 7120  /  done 7140  /  done 7160  /  done 7180  /  done 7200  /  done 7220  /  done 7240  /  done 7260  /  done 7280  /  done 7300  /  done 7320  /  done 7340  /  done 7360  /  done 7380  /  done 7400  /  done 7420  /  done 7440  /  done 7460  /  done 7480  /  done 7500  /  done 7520  /  done 7540  /  done 7560  /  done 7580  /  done 7600  /  done 7620  /  done 7640  /  done 7660  /  done 7680  /  done 7700  /  done 7720  /  done 7740  /  done 7760  /  done 7780  /  done 7800  /  done 7820  /  done 7840  /  done 7860  /  done 7880  /  done 7900  /  done 7920  /  done 7940  /  done 7960  /  done 7980  /  done 8000  /  done 8020  /  done 8040  /  done 8060  /  done 8080  /  done 8100  /  done 8120  /  done 8140  /  done 8160  /  done 8180  /  done 8200  /  done 8220  /  done 8240  /  done 8260  /  done 8280  /  done 8300  /  done 8320  /  done 8340  /  done 8360  /  done 8380  /  done 8400  /  done 8420  /  done 8440  /  done 8460  /  done 8480  /  done 8500  /  done 8520  /  done 8540  /  done 8560  /  done 8580  /  done 8600  /  done 8620  /  done 8640  /  done 8660  /  done 8680  /  done 8700  /  done 8720  /  done 8740  /  done 8760  /  done 8780  /  done 8800  /  done 8820  /  done 8840  /  done 8860  /  done 8880  /  done 8900  /  done 8920  /  done 8940  /  done 8960  /  done 8980  /  done 9000  /  done 9020  /  done 9040  /  done 9060  /  done 9080  /  done 9100  /  done 9120  /  done 9140  /  done 9160  /  done 9180  /  done 9200  /  done 9220  /  done 9240  /  done 9260  /  done 9280  /  done 9300  /  done 9320  /  done 9340  /  done 9360  /  done 9380  /  done 9400  /  done 9420  /  done 9440  /  done 9460  /  done 9480  /  done 9500  /  done 9520  /  done 9540  /  done 9560  /  done 9580  /  done 9600  /  done 9620  /  done 9640  /  done 9660  /  done 9680  /  done 9700  /  done 9720  /  done 9740  /  done 9760  /  done 9780  /  done 9800  /  done 9820  /  done 9840  /  done 9860  /  done 9880  /  done 9900  /  done 9920  /  done 9940  /  done 9960  /  done 9980  /  done 10000  /  done 10020  /  done 10040  /  done 10060  /  done 10080  /  done 10100  /  done 10120  /  done 10140  /  done 10160  /  done 10180  /  done 10200  /  done 10220  /  done 10240  /  done 10260  /  done 10280  /  done 10300  /  done 10320  /  done 10340  /  done 10360  /  done 10380  /  done 10400  /  done 10420  /  done 10440  /  done 10460  /  done 10480  /  done 10500  /  done 10520  /  done 10540  /  done 10560  /  done 10580  /  done 10600  /  done 10620  /  done 10640  /  done 10660  /  done 10680  /  done 10700  /  done 10720  /  done 10740  /  done 10760  /  done 10780  /  done 10800  /  done 10820  /  done 10840  /  done 10860  /  done 10880  /  done 10900  /  done 10920  /  done 10940  /  done 10960  /  done 10980  /  done 11000  /  done 11020  /  done 11040  /  done 11060  /  done 11080  /  done 11100  /  done 11120  /  done 11140  /  done 11160  /  done 11180  /  done 11200  /  done 11220  /  done 11240  /  done 11260  /  done 11280  /  done 11300  /  done 11320  /  done 11340  /  done 11360  /  done 11380  /  done 11400  /  done 11420  /  done 11440  /  done 11460  /  done 11480  /  done 11500  /  done 11520  /  done 11540  /  done 11560  /  done 11580  /  done 11600  /  done 11620  /  done 11640  /  done 11660  /  done 11680  /  done 11700  /  done 11720  /  done 11740  /  done 11760  /  done 11780  /  done 11800  /  done 11820  /  done 11840  /  done 11860  /  done 11880  /  done 11900  /  done 11920  /  done 11940  /  done 11960  /  done 11980  /  done 12000  /  done 12020  /  done 12040  /  done 12060  /  done 12080  /  done 12100  /  done 12120  /  done 12140  /  done 12160  /  done 12180  /  done 12200  /  done 12220  /  done 12240  /  done 12260  /  done 12280  /  done 12300  /  done 12320  /  done 12340  /  done 12360  /  done 12380  /  done 12400  /  done 12420  /  done 12440  /  done 12460  /  done 12480  /  done 12500  /  done 12520  /  done 12540  /  done 12560  /  done 12580  /  done 12600  /  done 12620  /  done 12640  /  done 12660  /  done 12680  /  done 12700  /  done 12720  /  done 12740  /  done 12760  /  done 12780  /  done 12800  /  done 12820  /  done 12840  /  done 12860  /  done 12880  /  done 12900  /  done 12920  /  done 12940  /  done 12960  /  done 12980  /  done 13000  /  done 13020  /  done 13040  /  done 13060  /  done 13080  /  done 13100  /  done 13120  /  done 13140  /  done 13160  /  done 13180  /  done 13200  /  done 13220  /  done 13240  /  done 13260  /  done 13280  /  done 13300  /  done 13320  /  done 13340  /  done 13360  /  done 13380  /  done 13400  /  done 13420  /  done 13440  /  done 13460  /  done 13480  /  done 13500  /  done 13520  /  done 13540  /  done 13560  /  done 13580  /  done 13600  /  done 13620  /  done 13640  /  done 13660  /  done 13680  /  done 13700  /  done 13720  /  done 13740  /  done 13760  /  done 13780  /  done 13800  /  done 13820  /  done 13840  /  done 13860  /  done 13880  /  done 13900  /  done 13920  /  done 13940  /  done 13960  /  done 13980  /  done 14000  /  done 14020  /  done 14040  /  done 14060  /  done 14080  /  done 14100  /  done 14120  /  done 14140  /  done 14160  /  done 14180  /  done 14200  /  done 14220  /  done 14240  /  done 14260  /  done 14280  /  done 14300  /  done 14320  /  done 14340  /  done 14360  /  done 14380  /  done 14400  /  done 14420  /  done 14440  /  done 14460  /  done 14480  /  done 14500  /  done 14520  /  done 14540  /  done 14560  /  done 14580  /  done 14600  /  done 14620  /  done 14640  /  done 14660  /  done 14680  /  done 14700  /  done 14720  /  done 14740  /  done 14760  /  done 14780  /  done 14800  /  done 14820  /  done 14840  /  done 14860  /  done 14880  /  done 14900  /  done 14920  /  done 14940  /  done 14960  /  done 14980  /  done 15000  /  done 15020  /  done 15040  /  done 15060  /  done 15080  /  done 15100  /  done 15120  /  done 15140  /  done 15160  /  done 15180  /  done 15200  /  done 15220  /  done 15240  /  done 15260  /  done 15280  /  done 15300  /  done 15320  /  done 15340  /  done 15360  /  done 15380  /  done 15400  /  done 15420  /  done 15440  /  done 15460  /  done 15480  /  done 15500  /  done 15520  /  done 15540  /  done 15560  /  done 15580  /  done 15600  /  done 15620  /  done 15640  /  done 15660  /  done 15680  /  done 15700  /  done 15720  /  done 15740  /  done 15760  /  done 15780  /  done 15800  /  done 15820  /  done 15840  /  "
     ]
    }
   ],
   "source": [
    "\n",
    "all_result=[]\n",
    "\n",
    "input_seq=full_seq\n",
    "len_of_aso=17\n",
    "\n",
    "\n",
    "mask_seq='N'*17\n",
    "\n",
    "best_total=0.0\n",
    "\n",
    "for now_mut_pos in range(acceptor_pos-5022,donor_pos+5020):\n",
    "    \n",
    "    original_seq = input_seq\n",
    "    masked_seq = input_seq[:now_mut_pos] + mask_seq + input_seq[now_mut_pos+len_of_aso:]\n",
    "\n",
    "\n",
    "    original_donor_seq = original_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    original_acceptor_seq = original_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    masked_donor_seq = masked_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    masked_acceptor_seq = masked_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    original_donor_prob = get_prob_with_seq(original_donor_seq)[0][0][2]\n",
    "    original_acceptor_prob = get_prob_with_seq(original_acceptor_seq)[0][0][1]\n",
    "\n",
    "    masked_donor_prob = get_prob_with_seq(masked_donor_seq)[0][0][2]\n",
    "    masked_acceptor_prob = get_prob_with_seq(masked_acceptor_seq)[0][0][1]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    result_total = (masked_donor_prob+masked_acceptor_prob)/2.0\n",
    "    delta_acceptor = masked_acceptor_prob - original_acceptor_prob\n",
    "    delta_donor = masked_donor_prob - original_donor_prob\n",
    "    delta_total = delta_acceptor + delta_donor\n",
    "    delta_pos = now_mut_pos\n",
    "    erased_seq = input_seq[now_mut_pos:now_mut_pos+17]\n",
    "\n",
    "    all_result.append( [delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq] )\n",
    "        \n",
    "        \n",
    "    f = open(\"ASO_result_renew.txt\", 'a')\n",
    "    \n",
    "    def inline_str(str_list):\n",
    "        num = len(str_list)\n",
    "        ret=\"\"\n",
    "        for i in range(num):\n",
    "            ret+=str(str_list[i])\n",
    "            if i<num-1:\n",
    "                ret+='\\t'\n",
    "        ret+='\\n'\n",
    "        return ret\n",
    "        \n",
    "    \n",
    "    f.write(inline_str([result_total,delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq,original_acceptor_prob,original_donor_prob,masked_acceptor_prob,masked_donor_prob]))\n",
    "    f.close()\n",
    "    \n",
    "    if now_mut_pos%20==0:\n",
    "        print('done '+str(now_mut_pos),end=\"  /  \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-monkey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-vermont",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-italic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-supervisor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-iceland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-success",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-nelson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-ordinary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-vinyl",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-silly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-watts",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-encounter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-baker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-whale",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-belle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-mortgage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-viking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "irish-cornwall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 760  /  done 780  /  done 800  /  done 820  /  done 840  /  done 860  /  done 880  /  done 900  /  done 920  /  done 940  /  done 960  /  done 980  /  done 1000  /  done 1020  /  done 1040  /  done 1060  /  done 1080  /  done 1100  /  done 1120  /  done 1140  /  done 1160  /  done 1180  /  done 1200  /  done 1220  /  done 1240  /  done 1260  /  done 1280  /  done 1300  /  done 1320  /  done 1340  /  done 1360  /  done 1380  /  done 1400  /  done 1420  /  done 1440  /  done 1460  /  done 1480  /  done 1500  /  done 1520  /  done 1540  /  done 1560  /  done 1580  /  done 1600  /  done 1620  /  done 1640  /  done 1660  /  done 1680  /  done 1700  /  done 1720  /  done 1740  /  done 1760  /  done 1780  /  done 1800  /  done 1820  /  done 1840  /  done 1860  /  done 1880  /  done 1900  /  done 1920  /  done 1940  /  done 1960  /  done 1980  /  done 2000  /  done 2020  /  done 2040  /  done 2060  /  done 2080  /  done 2100  /  done 2120  /  done 2140  /  done 2160  /  done 2180  /  done 2200  /  done 2220  /  done 2240  /  done 2260  /  done 2280  /  done 2300  /  done 2320  /  done 2340  /  done 2360  /  done 2380  /  done 2400  /  done 2420  /  done 2440  /  done 2460  /  done 2480  /  done 2500  /  done 2520  /  done 2540  /  done 2560  /  done 2580  /  done 2600  /  done 2620  /  done 2640  /  done 2660  /  done 2680  /  done 2700  /  done 2720  /  done 2740  /  done 2760  /  done 2780  /  done 2800  /  done 2820  /  done 2840  /  done 2860  /  done 2880  /  done 2900  /  done 2920  /  done 2940  /  done 2960  /  done 2980  /  done 3000  /  done 3020  /  done 3040  /  done 3060  /  done 3080  /  done 3100  /  done 3120  /  done 3140  /  done 3160  /  done 3180  /  done 3200  /  done 3220  /  done 3240  /  done 3260  /  done 3280  /  done 3300  /  done 3320  /  done 3340  /  done 3360  /  done 3380  /  done 3400  /  done 3420  /  done 3440  /  done 3460  /  done 3480  /  done 3500  /  done 3520  /  done 3540  /  done 3560  /  done 3580  /  done 3600  /  done 3620  /  done 3640  /  done 3660  /  done 3680  /  done 3700  /  done 3720  /  done 3740  /  done 3760  /  done 3780  /  done 3800  /  done 3820  /  done 3840  /  done 3860  /  done 3880  /  done 3900  /  done 3920  /  done 3940  /  done 3960  /  done 3980  /  done 4000  /  done 4020  /  done 4040  /  done 4060  /  done 4080  /  done 4100  /  done 4120  /  done 4140  /  done 4160  /  done 4180  /  done 4200  /  done 4220  /  done 4240  /  done 4260  /  done 4280  /  done 4300  /  done 4320  /  done 4340  /  done 4360  /  done 4380  /  done 4400  /  done 4420  /  done 4440  /  done 4460  /  done 4480  /  done 4500  /  done 4520  /  done 4540  /  done 4560  /  done 4580  /  done 4600  /  done 4620  /  done 4640  /  done 4660  /  done 4680  /  done 4700  /  done 4720  /  done 4740  /  done 4760  /  done 4780  /  done 4800  /  done 4820  /  done 4840  /  done 4860  /  done 4880  /  done 4900  /  done 4920  /  done 4940  /  done 4960  /  done 4980  /  done 5000  /  done 5020  /  done 5040  /  done 5060  /  done 5080  /  done 5100  /  done 5120  /  done 5140  /  done 5160  /  done 5180  /  done 5200  /  done 5220  /  done 5240  /  done 5260  /  done 5280  /  done 5300  /  done 5320  /  done 5340  /  done 5360  /  done 5380  /  done 5400  /  done 5420  /  done 5440  /  done 5460  /  done 5480  /  done 5500  /  done 5520  /  done 5540  /  done 5560  /  done 5580  /  done 5600  /  done 5620  /  done 5640  /  done 5660  /  done 5680  /  done 5700  /  done 5720  /  done 5740  /  done 5760  /  done 5780  /  done 5800  /  done 5820  /  done 5840  /  done 5860  /  done 5880  /  done 5900  /  done 5920  /  done 5940  /  done 5960  /  done 5980  /  done 6000  /  done 6020  /  done 6040  /  done 6060  /  done 6080  /  done 6100  /  done 6120  /  done 6140  /  done 6160  /  done 6180  /  done 6200  /  done 6220  /  done 6240  /  "
     ]
    }
   ],
   "source": [
    "\n",
    "all_result=[]\n",
    "\n",
    "input_seq=intron_exon_intron\n",
    "len_of_aso=17\n",
    "\n",
    "\n",
    "mask_seq='N'*17\n",
    "\n",
    "best_total=0.0\n",
    "\n",
    "for now_mut_pos in range(len(input_seq)-len_of_aso+1):\n",
    "    if now_mut_pos<750 or now_mut_pos>11000:\n",
    "        continue\n",
    "    \n",
    "    original_seq = input_seq\n",
    "    masked_seq = input_seq[:now_mut_pos] + mask_seq + input_seq[now_mut_pos+len_of_aso:]\n",
    "\n",
    "    original_seq = left_context + original_seq + right_context\n",
    "    masked_seq = left_context + masked_seq + right_context\n",
    "\n",
    "\n",
    "    original_donor_seq = original_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    original_acceptor_seq = original_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    masked_donor_seq = masked_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    masked_acceptor_seq = masked_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    original_donor_prob = get_prob_with_seq(original_donor_seq)[0][0][2]\n",
    "    original_acceptor_prob = get_prob_with_seq(original_acceptor_seq)[0][0][1]\n",
    "\n",
    "    masked_donor_prob = get_prob_with_seq(masked_donor_seq)[0][0][2]\n",
    "    masked_acceptor_prob = get_prob_with_seq(masked_acceptor_seq)[0][0][1]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    result_total = (masked_donor_prob+masked_acceptor_prob)/2.0\n",
    "    delta_acceptor = masked_acceptor_prob - original_acceptor_prob\n",
    "    delta_donor = masked_donor_prob - original_donor_prob\n",
    "    delta_total = delta_acceptor + delta_donor\n",
    "    delta_pos = now_mut_pos\n",
    "    erased_seq = input_seq[now_mut_pos:now_mut_pos+17]\n",
    "\n",
    "    all_result.append( [delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq] )\n",
    "        \n",
    "        \n",
    "    f = open(\"ASO_result_renew.txt\", 'a')\n",
    "    \n",
    "    def inline_str(str_list):\n",
    "        num = len(str_list)\n",
    "        ret=\"\"\n",
    "        for i in range(num):\n",
    "            ret+=str(str_list[i])\n",
    "            if i<num-1:\n",
    "                ret+='\\t'\n",
    "        ret+='\\n'\n",
    "        return ret\n",
    "        \n",
    "    \n",
    "    f.write(inline_str([result_total,delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq,original_acceptor_prob,original_donor_prob,masked_acceptor_prob,masked_donor_prob]))\n",
    "    f.close()\n",
    "    \n",
    "    if now_mut_pos%20==0:\n",
    "        print('done '+str(now_mut_pos),end=\"  /  \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-device",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-eugene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-illinois",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-missile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-texture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stable-correspondence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6251"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seq)-len_of_aso+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "every-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"ASO_result.txt\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sustained-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "\n",
    "\n",
    "for line in f:\n",
    "    p=line.split('\\t')\n",
    "    res.append([float(p[0]),p[4],int(p[3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sonic-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.28564858, 'CCAGCATTATGAAAGTG', 5832],\n",
       " [0.2863837, 'TTAGACAAAATCAAAAA', 5773],\n",
       " [0.28948206, 'GTGCTCACATTCCTTAA', 5798],\n",
       " [0.2931587, 'TGCCAGCATTATGAAAG', 5830],\n",
       " [0.3000751, 'TTTTAGACAAAATCAAA', 5771],\n",
       " [0.30198628, 'GTTTTAGACAAAATCAA', 5770],\n",
       " [0.3060084, 'CATTCCTTAAATTAAGG', 5805],\n",
       " [0.30910528, 'CTGCCAGCATTATGAAA', 5829],\n",
       " [0.31307673, 'ACATTCCTTAAATTAAG', 5804],\n",
       " [0.3230291, 'ATTCCTTAAATTAAGGA', 5806]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort()\n",
    "res[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-nerve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-objective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-arlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-harmony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-audit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-tonight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "treated-shepherd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "portable-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mutation(input_seq, donor_pos, acceptor_pos, len_of_aso ,use_n_as_aso=True):\n",
    "    \n",
    "#     total_delta=0.8\n",
    "#     acceptor_delta=0.5\n",
    "#     donor_delta=0.3\n",
    "#     delta_pos=536\n",
    "#     erased_seq='ATTTGGCCAAGCGATGC'\n",
    "    \n",
    "    \n",
    "#     all_result.append([[total_delta,acceptor_delta,donor_delta,delta_pos,erased_seq]])\n",
    "    \n",
    "    \n",
    "    all_result=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if use_n_as_aso:\n",
    "        mask_seq='N'*len_of_aso\n",
    "    else:\n",
    "        mask_seq=make_random_seq(len_of_aso)\n",
    "    \n",
    "    best_total=0.0\n",
    "    \n",
    "    for now_mut_pos in range(len(input_seq)-len_of_aso+1):\n",
    "        original_seq = input_seq\n",
    "        masked_seq = input_seq[:now_mut_pos] + mask_seq + input_seq[now_mut_pos+len_of_aso:]\n",
    "        \n",
    "        original_seq = left_context + original_seq + right_context\n",
    "        masked_seq = left_context + masked_seq + right_context\n",
    "        \n",
    "        \n",
    "        original_donor_seq = original_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "        original_acceptor_seq = original_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "        \n",
    "        \n",
    "        masked_donor_seq = masked_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "        masked_acceptor_seq = masked_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "        \n",
    "\n",
    "        original_donor_prob = get_prob_with_seq(original_donor_seq)[0][0][2]\n",
    "        original_acceptor_prob = get_prob_with_seq(original_acceptor_seq)[0][0][1]\n",
    "        \n",
    "        masked_donor_prob = get_prob_with_seq(masked_donor_seq)[0][0][2]\n",
    "        masked_acceptor_prob = get_prob_with_seq(masked_acceptor_seq)[0][0][1]\n",
    "        \n",
    "        \n",
    "        delta_acceptor = masked_acceptor_prob - original_acceptor_prob\n",
    "        delta_donor = masked_donor_prob - original_donor_prob\n",
    "        delta_total = delta_acceptor + delta_donor\n",
    "        delta_pos = now_mut_pos\n",
    "        erased_seq = input_seq[now_mut_pos:now_mut_pos+17]\n",
    "        \n",
    "        all_result.append( [delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq] )\n",
    "      \n",
    "        best_total = max(best_total,delta_total)\n",
    "    \n",
    "        if now_mut_pos%20==0:\n",
    "            print('done '+str(now_mut_pos),end=\"  /  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0  /  done 10  /  done 20  /  done 30  /  done 40  /  done 50  /  done 60  /  done 70  /  done 80  /  done 90  /  done 100  /  done 110  /  done 120  /  done 130  /  done 140  /  done 150  /  done 160  /  done 170  /  done 180  /  done 190  /  done 200  /  done 210  /  done 220  /  done 230  /  done 240  /  done 250  /  done 260  /  done 270  /  done 280  /  done 290  /  done 300  /  done 310  /  done 320  /  done 330  /  done 340  /  done 350  /  done 360  /  done 370  /  done 380  /  done 390  /  done 400  /  done 410  /  done 420  /  done 430  /  done 440  /  done 450  /  done 460  /  done 470  /  done 480  /  done 490  /  done 500  /  done 510  /  done 520  /  done 530  /  done 540  /  done 550  /  done 560  /  done 570  /  done 580  /  done 590  /  done 600  /  done 610  /  done 620  /  done 630  /  done 640  /  done 650  /  done 660  /  done 670  /  done 680  /  done 690  /  done 700  /  done 710  /  done 720  /  done 730  /  done 740  /  done 750  /  done 760  /  done 770  /  done 780  /  done 790  /  done 800  /  done 810  /  done 820  /  done 830  /  "
     ]
    }
   ],
   "source": [
    "predict_mutation(intron_exon_intron,donor_pos,acceptor_pos,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-trustee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "5초에 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-transcription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-triangle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-prize",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-governor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mutation(intron_exon_intron,donor_pos,acceptor_pos,17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spliceai",
   "language": "python",
   "name": "spliceai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
