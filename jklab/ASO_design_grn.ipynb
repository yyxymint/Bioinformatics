{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selected-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pkg_resources import resource_filename\n",
    "from utils2 import one_hot_encode\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import average_precision_score\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-negotiation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decent-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ('snp_data/spliceai{}.h5'.format(x) for x in [1,2,3,4,5])\n",
    "spliceai_models=[load_model(resource_filename('spliceai', x),compile=False) for x in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-christianity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_seq(seq_len):\n",
    "    \n",
    "    random_seq=''\n",
    "    for _ in range(seq_len):\n",
    "        xx=random.random()\n",
    "        \n",
    "        if xx<0.25:\n",
    "            random_seq+='A'\n",
    "        elif xx<0.5:\n",
    "            random_seq+='T'\n",
    "        elif xx<0.75:\n",
    "            random_seq+='G'\n",
    "        else:\n",
    "            random_seq+='C'\n",
    "    \n",
    "    return random_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "annoying-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_context='tgcaggccgcagtgagctatgatcagcttgggcgactgagcgagaccctgtctctaaaacaaacacacaaGTccgggcgcggtggctcatgcctgtaatcttagcactttgggaggccgaggtgggcggatcacgaggtcaagaaatcgagaccatcctggccaacatggtgaaaccccgtctctactaaaaatacaaaaattagctgggcgtggtggtgcgcgcctgtagtcccagctactcgggaggctgaggcaggagaatcgcttgaacccgggaggcagaggttgcagtgagccgagatcgtgccactgcactccagcctggcgacagagtgagactccgtctcagaacaaacaaacaaaaggatagaaaGGCGAGCACAAATATTCCCAATTCATAACACTCCCTCGCACTGTCAATGCCCCAGACACGCGCTATCATCTCTAGCAAACTCCCCCAGGCGCCTGCAGGATGGGTTAAGGAAGGCGACGAGCACCAGCTGCCCTGCTGAGGCTGTCCCGACGTCACATGATTCTCCAATCACATGATCCCTAGAAATGGGGTGTGGGGCGAGAGGAAGCAGGGAGGAGAGTGATTTGAGTAGAAAAGAAACACAGCATTCCAGGCTGGCCCCACCTCTATATTGATAAGTAGCCAATGGGAGCGGGTAGCCCTGATCCCTGGCCAATGGAAACTGAGGTAGGCGGGTCATCGCGCTGGGGTCTGTAGTCTGAGCGCTACCCGGTTGCTGCTGCCCAAGGACCGCGGAGTCGGACGCAGGTAGGAGAGCGGCCGCGCAGACCTCTCGCCTGCTCCTGCCCAGGGGCCCGCCAGGGCCATGTGAGCTTGAGGTTCCCCTGGAGTCTCAGCCGGAGACAACAGAAGAACCGCTTACTGAAACTCCTTGGGGGTTCTGATACACTAGGGGGAGTTTTATGGGAAAGAGGAAGCAGTAATTGCAGTGACGCCCCGTTAGAAGGGGCTTTCTACCTCCCCAGCATTCCCCCAAAGCAGGGACCACACCATTCTTGACCCAGCTCCACCCCTGTCGGTAGGTGCTGGCTTCTTCCCCTCTCCTGGTGGTGGTGGGTGGTTCCCGCGGCGGCCTGGAGCCGGAGGGGCGCGCGACCCTGGGCTGGGAGCTCCGAGGGCCTGGGAACGAGACCTGAGACCTTGGCTTCTCGAAGGTAGTAGGGACTTGGGAGTGGTGACTGAACCTGGTCTGGCTCCTCCTTACTTCCTCTTGTTGCGGGTGGGACGAGCTAGCTTCCGCCTCTCCCAGCCACTTTTTCCTGCTCATTTGCAGCTAGGTTGGCTCCCCTTTTGGGAATTTCCTCTCCCCTTGGCACTCGGAGTTGGGGGGTGCCACCTAGTGGAAGATAACGGAGCTAGGGTCTTGAAGAGGCTGCTGTCCCCTCTGGCTGTTTTGGCGGTGTAGGGTGGCATGAGAGACTGCGACTCGCCTCCTCATCCCTGTTTCTGTATGCGAGTGCTTGTATTCAGTAGAAGCATACACTATACTCCCTCAATTTAGGGTAAACAGGAGGGGCCACATGCACAGGTAATTCACCAGGGAGCCGAACACTCCTGTGCAGACAGACTCCCCTTCCCAGCAAGCCATGGCAGCGGACAGCCTGCTGAGAACACCCAGGAAGCAGGCGGTGCCAGCTGCAGGTGCTTTGCCTGGGAGCTGTGGGGCTGAGGAGAGGGTCCACTGTCCAGGACCAGTGAACTTCATCCTTATCTGTCCAGGAGGTGGCCTCTTGGGGATGCTGAGTTAGGGGAGGGGCACTTGAGGAAAGCCAGGTGGAGCAGAGAGGATGTGAGTGACTGGGTGGGTGAGATTTCCTGCCCCTCCCCCCGCAGTGGtatccacacctagactcgtggggtaactgaggcacagacagagagcaacttctcaggccctcacagttggcaattctaggattaggacccaagtgcgattttcaggcagtccctgtaccctgtttctgttgtacctgttgcaccATTCCCAGGCACTGCCCATCGTGCCACTAGTGATATGAACCCAGGTCCAATACGCTCTGGGGCCATCAAAGCCTGACGTCACCATGACCTGATGTGTGACGTGTTATaggtgtcccttggtatcttcacggaactggttccaggaccccaaaatctgtgggtgctcaagcccctgagataaaatggtgtaatatttgcatataacctatacatactttaaatcatttctagattacttatacctaatacaatggaaatgacatgtcggctgggcgtggtggctcatgcctgtaatcccaccactttgggaggccgtggcaggtggatcacctgaggtctggagtttgagaccagcctgaccaacatggtgaaacccccatctctactaaaaatacaaaaattagccaggtgtggtagcgcacacctataatcccacctacttgggaggctgaggcaggagaattgcttgaacctgggaggcggagttcgcagtaagctgagatcgcgccactgtactacagcctgggtgacagagcaggactccatctcaaaaaaaaaagagaaaaagaaaaagaaatgccatgtaaatagttgtgatcctgaattgtttagggaataataagaaagaactatctgtagatgttcagtatagatgcacccatcGTAAGCCTAACTACATTGTATAACTCAGCAACGATGTAACATTTTCAGGGGtttttttgttttgttttttgagacagaatctcagtctcactctgtcacccaggctggagtatgttggcgtgatctctgctcactgcaacctccacctcctgggctcaagcgattctcctgcctcagcctcttgagtagctgggattgcaggtgtgcgctaccacgcatggctaatttttgtatttttaatagagatggggttttaccacgttggtcaggctggtcttgaactcctgaccttgggatccgcccacctgggcctcccaaagtgctgggattacaggcgttagccaccgcgcccAATATATTTTGATCCCTGGTTGGATATGGAGGGCTGACTGtacttaacatctctaagcttcagtttcctcctttaaaataaaggtgtggctgggtgtggtggttcaagcctgtaatcccagcacttagggaggctgaggtgggtggatcagctgaggtcaggagttcaagaccagcctgaccaatatggtgaaaccccctctctgctaaaaatacaaaaattagccaggcgtggtggcgagcgcctgtagtcccagctacttgcttgaacttgggaggcagaggttgcagtgagctgagatcgtgccactgaactcgagcatgggcaacagagcaagactgtctcaaaaaaaaaaaaaaaaaGGGGGTGAGcagacgtggtggcacgctcccacagtcccagctacttagtaggaggccaaggttggaggattgcttgatcccaggagtctgagtccagcctgggcaacatggcaatacctcatctctaaaaataaaataaaagtaaaggtattaattactactttggatggttgttgcaaagaaatatatataaaataatggagagtcttgtaactggctcccaagaggctcaacagacattACTGTTTTTGCTTCTTCATTATGAGTTACCTCTCTGGCCACCCCACTGAACTAGCTGGGCTAGCTGAGCCTGGGAGAAGAGTTGTTTAGGAAGTGAGAGGCTGCTCTCCACAGAGACTCAAGGCTCAGTTCCTCCTGGTGACTCAGATGGGCAGCCCAGTGGGCACACGTGGTCTCTCTCCACATGTGGCTGAGTTTCACTTCCAGAATAGATGGAGAGGCAAGGGCAGGGTTTAGCATGCTTGAGGAATCTCAGAGGGCCCTGGTGGTGTGGGGGACCCTCAGAACACAGGTGTCTCAAGGGCTGACCCAGCTTCTGTGTCCTTTTCTCTGGGTGAGGAGGGGACATTCATGGGCAGATGGTGACCTCTGGGGAAGGCAGCCCAGACTCCACTGGCCACCATATTTCCTTTTTCACAACTTTCTCACCCCTGTGGTTTCCCATGTCATCATGTGGCCGCTTCCCGCAAGGCCTTAGCGGGGTGCAGGTATGAACATAGTGTCAGGCAAGGAGGCATCTGGAGGGGAACCCTGGCTTTTCCTGGGGGGACTCCCTCCCTGCACCCTAGCCCTGTCCTCTCCCATGGCTACTGATGCCTTCCCCTCACCCCAGAGGTGGCCCACATCTGCACAGATCAGACCCACAAAAATCACGTCTTCCTGACTCTCATAAGCCTGCCCAGTGAGGCCCAGGCATTAGGCCATGTGCTGGGGACTCAGACCCACACATATACGCATGTCAGCATTCATGCTTACAGGTCCGCACATGCTGGGGCAAGTGTCACACACGGGGCGCTGTAGGAAGCTGACTCTCAGCCCCTGCAGATTTCTGCCTGCCTGGACAGGGAGGTGTTGAGAAGGCTCAGGCAGTCCTGGGCCAGGACCTTGGCCTGGGGCTAGGGTACTGAGTGACCCTAGAATCAAGGGTGGCGTGGGCTTAAGCAGTTGCCAGACGTTCCTTGGTACTTTGCAGGCAGACCATGTGGACCCTGGTGAGCTGGGTGGCCTTAACAGCAGGGCTGGTGGCTGGAACGCGGTGCCCAGATGGTCAGTTCTGCCCTGTGGCCTGCTGCCTGGACCCCGGAGGAGCCAGCTACAGCTGCTGCCGTCCCCTTCTGGTGAGTGCCCCTCAGCCTAGGCAAGAGCTGGCAGCCTGGGTTTTCCCAAAGGGTCATCTTGGATTGGCCAGAGGAGGACGCCAGGCACAAGTCTGTGGTTTATCATTTTCCCTGTCTTTCTAGGACAAATGGCCCACAACACTGAGCAGGCATCTGGGTGGCCCCTGCCAGGTTGATGCCCACTGCTCTGCCGGCCACTCCTGCATCTTTACCGTCTCAGGGACTTCCAGTTGCTGCCCCTTCCCAGAG'.upper()\n",
    "right_context='GTAACAACTCCGTGGGTGCCATCCAGTGCCCTGATAGTCAGTTCGAATGCCCGGACTTCTCCACGTGCTGTGTTATGGTCGATGGCTCCTGGGGGTGCTGCCCCATGCCCCAGGTACAAATCtgggggagatgggggtatgtggagggaagtgggggcagagttgggggccaggggcagggggTGAAGACGGAGTCAGGACCATTTTTTCTCAGGCTTCCTGCTGTGAAGACAGGGTGCACTGCTGTCCGCACGGTGCCTTCTGCGACCTGGTTCACACCCGCTGCATCACACCCACGGGCACCCACCCCCTGGCAAAGAAGCTCCCTGCCCAGAGGACTAACAGGGCAGGTGAGGAGGTGGGAGAGCATCAGGCCAGGGGCTGGGGCGGGGCCTCATTGACTCCAAGTGTAGGAAAAAGTTTCCTCCATCCTGGCTGCCCCTCACGTTTGCTCCTCTTCCAGTGGCCTTGTCCAGCTCGGTCATGTGTCCGGACGCACGGTCCCGGTGCCCTGATGGTTCTACCTGCTGTGAGCTGCCCAGTGGGAAGTATGGCTGCTGCCCAATGCCCAACGTGAGTGAGGGGCTGGAGCCAGCTTGGCTGTGTGCCCCCAGCCACCTGGCCCTGACACGCACCTTACAGGGGCTCTGTGGCATGGGGCTGGCTGGCTGCTTGCTGGGAGCCTGGCTGATGCAGGGTTCATGCTACCCCCTAGTGGGGGATTGGGGCAGTGCCAGCCATCAGCCTGGCTGCTCCCTGTGTGCTACTGAGCCTGGAAGTGACAAAGACCCACCCCTGTCCCCACTCAGGCCACCTGCTGCTCCGATCACCTGCACTGCTGCCCCCAAGACACTGTGTGTGACCTGATCCAGAGTAAGTGCCTCTCCAAGGAGAACGCTACCACGGACCTCCTCACTAAGCTGCCTGCGCACACAGGTACCAGAGGCAGGGTGCAGATACAGGGGTGGGGCCCCCTTTCCTCCCTTTTAGGCCTGGCCTTAGGATCACTGCAAGGTGGTGTAAGCGGTACCCTCCATCTTCAACACCTGGTTCCAGCTGTGGAGCCGGCAAAGGGTTGATACCCCTGAGGGTCCCCAGTGCCACTTCTGACCTGTCCTCTCTGCTTCCCTCACAGTGGGGGATGTGAAATGTGACATGGAGGTGAGCTGCCCAGATGGCTATACCTGCTGCCGTCTACAGTCGGGGGCCTGGGGCTGCTGCCCTTTTACCCAGGTACCCAGGGGTGGCGGGTGGGTGGGCTGAGCACAGTGTGGCAGGCAGCCGGGCCCCAGTGCCCACCTGCCCTTCTTCATCTGCCCTAGGCTGTGTGCTGTGAGGACCACATACACTGCTGTCCCGCGGGGTTTACGTGTGACACGCAGAAGGGTACCTGTGAACAGGGGCCCCACCAGGTGCCCTGGATGGAGAAGGCCCCAGCTCACCTCAGCCTGCCAGACCCACAAGCCTTGAAGAGAGATGTCCCCTGTGATAATGTCAGCAGCTGTCCCTCCTCCGATACCTGCTGCCAACTCACGTCTGGGGAGTGGGGCTGCTGTCCAATCCCAGAGGTATATGGGAGGGGACAGCATCTTGGCCTGGGCAGGTGGGTGGCCAAGCTCCTATTGCTTTCTGCCCTCCGCATAGCCCATAGGTGATACCCAGCTCTGACAGATTCGTCCCCAGCTGGAGGTGCTGTAAGCAGGAGAGGCGGGCTGGAGTAGGTAGGGGCTCGGCACTGCGCCCCACATAGTGGCTACCTACAACGCCCTTTCCTGCCCACCCCCCAGGCTGTCTGCTGCTCGGACCACCAGCACTGCTGCCCCCAGGGCTACACGTGTGTAGCTGAGGGGCAGTGTCAGCGAGGAAGCGAGATCGTGGCTGGACTGGAGAAGATGCCTGCCCGCCGGGCTTCCTTATCCCACCCCAGAGACATCGGCTGTGACCAGCACACCAGCTGCCCGGTGGGGCAGACCTGCTGCCCGAGCCTGGGTGGGAGCTGGGCCTGCTGCCAGTTGCCCCATGTGAGTGCCTCCCTGCCTGCCCCTGGATAGGGGAGCTAAGCCCAGTGAGGGGACAGGAACATAATGCCATTCTGTGCTCCCTTCCCCGCCAGGCTGTGTGCTGCGAGGATCGCCAGCACTGCTGCCCGGCTGGCTACACCTGCAACGTGAAGGCTCGATCCTGCGAGAAGGAAGTGGTCTCTGCCCAGCCTGCCACCTTCCTGGCCCGTAGCCCTCACGTGGGTGTGAAGGACGTGGAGTGTGGGGAAGGACACTTCTGCCATGATAACCAGACCTGCTGCCGAGACAACCGACAGGGCTGGGCCTGCTGTCCCTACCGCCAGGTCAGTGCCAACCCCCATCCTGGGGCTGGGTATGGCCAGGGACCAGGTCCCACCTCGTCCAACCCTCTCGCCCCCCTCTGACCATCCAGGGCGTCTGTTGTGCTGATCGGCGCCACTGCTGTCCTGCTGGCTTCCGCTGCGCAGCCAGGGGTACCAAGTGTTTGCGCAGGGAGGCCCCGCGCTGGGACGCCCCTTTGAGGGACCCAGCCTTGAGACAGCTGCTGTGAGGGACAGTACTGAAGACTCTGCAGCCCTCGGGACCCCACTCGGAGGGTGCCCTCTGCTCAGGCCTCCCTAGCACCTCCCCCTAACCAAATTCTCCCTGGACCCCATTCTGAGCTCCCCATCACCATGGGAGGTGGGGCCTCAATCTAAGGCCTTCCCTGTCAGAAGGGGGTTGTGGCAAAAGCCACATTACAAGCTGCCATCCCCTCCCCGTTTCAGTGGACCCTGTGGCCAGGTGCTTTTCCCTATCCACAGGGGTGTTTGTGTGTGTGCGCGTGTGCGTTTCAATAAAGTTTGTACACTTTCTTAACAGTGTCTGATTTGCCGCCCTGCCTGCCCTCCCCAGGGCCCCAGAACAGGGGTTCACGTCCACTGCCAACACTCCCCTCCCCTACCCCACAGAAAGACATACACAGCCTTAACCTCACCAGTTTTATATTTGCTGCTGCCCACATCGGCTGTATCACATTACCCCCTAGTCCCCAGAGCTGTCCCAGCCACCAGCCCTGTGACATCGTAGCCCAGAGATGGGCTAGTCAGCAAGCAGCACCCCCTCCCCTCCCAGGGGTCCACAAAGAACGCCCCCTCCCTTCCCAGCCCTCACACTAGCAGCTGAGGCTGGGTCACCCCTCCTGCTTTCCCACAATAGAGCTTTCTATGTACAGCCACGTCTACACAGGCACTGCTTCcccccagccctcctccccggcacctccccgtgggggtctggaccccccctcctccccGGCTTGGAGGCAGACACAGGGTCCCTTGCAAGACACGACCCAGCACCAACCACGGAACAGCTCCAAGGCCCCTGGGCCCCTCTCCGGCCTGGGGCTGGGAGCTacgcgcgagggcccccgcgggcccccggggcgcgcaccctgggtgcgggcccgcgcgggaggggCGGTGCCAGGCCCTGCGCGGGCGCTACTTGACGTTGAACACCATCAGCGGCCGCTCCTCCCGCCGCTGCCACGGGCTCTTCTTGTCTCCCGCCTCGTCGCCCACCTCCGCCCCCAGCTCGTCCTCCGGGCTGGTGAGCGAGTCGCGCCGCAGCTCGCTGGCGCTGCTGCGGGAGCTGTCCCCGCGGCTGCGGCCCCGCCCCCGGGGTACCGTGGCCGCCCGGCCCTCGGGCGCCGCCACCTCGTCCAGCAGCGGCGTCAGCGAGTTGTCCTCCGGAGAGCAGAGGCCCGTGCGGCTCTCGCTGCTGCTGGGCTCCGTGTCCTCGCTGAgcgccaggcgcgggggcgcgggcggcggcggcggcgcggcaggcggggcgcgctcccgctcctccctcgcgggccggcggcgcgcggGCCGCGCCTCGTGGACATCTACGCCCGAGTCCAGGCTGGCGTCGGTGCTGCGTGCCCCGCCGCCCGCCTGCAGGTCGATGTAAGAGTGGCGCACTTGCGAGTTGGAGCGCCCGTCGAGGGACACGAACCAGGCGCGCGGGTGCGGCTTCACGCCCAGTTCCAGCAGCTTCTTCTCGGTCAGGGCCTGCAGCTCCCCGTTGAGCTGCGCCATGGTGGACTCGTTGAATAGCACAGGGATGGTGACTGAGCCACTGACGGGcgccgcgcgcccggccccccagccctcgccgccgcccccgccgccctcgccccccgggcccgagtggcccgGCATCTGCGGGCGCTGGGGGTCGGGCTGGGGAAAAGCGCGCGCCGGGCCGGGTGCCGTGCCCTCCGGCGGGGCCGGCTCGTCGCCCACGCCGGCGGCGCCCGCCTCGCCGCCGAGGCGCACGTAGTGCGCGGGGATCACCAGGGTGGGCATGACGTTGCGGTAGACGTTGTCCTTGAGGTGGTCGATGGAGCCGCAGAAGATGAGCTGCCCCGCCTGGCCCAGCGACGGCGGCCGCGCCAGCTGGTCCACCGACTGCGACAGCAGGAAGTCGGGGGTCTTGCCCTCGGCCGCCCCCTTGTGGCCCAGGTAGTGGTCGAAGGGCGGCGGCGGCGAGGGCGGCTCGTGCAGGAAGGCCGCAGCCCCCGAGGGCCCCCGCCGGTGCTCCTCTAGGCCGGGCTCCAGCCCGCCGGGGCCCTCGGCCGAGCGAGCGCCCTTGAGCCCGGCGCTCTCGCCCCCGCGGGCACCCGAAGGCTCGGCGGCCGGGCGGCTGGCAGAGCGCGGCTTGGTGCGGAAGAAGTCATCCCGGGAGGAGGCCAAGTCCCGGGAGCTGGAGAAGGCCGAGTGGAGGGGGCCTGGAGGCGGAGCCTCGGGGTCCCCCGACGGGGCGGGTTCCAGGGGTCCCCCACAGATGAGGTGGAGCTGGGACATCGAGGTGGCCTGGTCTCGTTTGTTACCGTCAGAGGGCCCCGAGAGCTGCAGCTTGCGGTGCTGTTGCCTCGGCTTCAGGCAGCGCCTCCTGGAAGGGAGGGAGCAGAAGGGGCCGCTCAGGAAA'.upper()\n",
    "intron_exon_intron = 'GTGAGCGTGCCATCAGCCCAGTGGAGGGGCTTAGGTCTGCATTTATGCTTTTCCTGCACTCTACCACCTGCAGATAAAAGGGCCCTGCCAATGCAGGTTTCTCTGTGTTCCACAGGCCGTGGCATGCGGGGATGGCCATCACTGCTGCCCACGGGGCTTCCACTGCAGTGCAGACGGGCGATCCTGCTTCCAAAGATCAGGTGCAGCTGGGGTGTGGGTGCAGGGCAGGCAGACGGGCAGCATGTGGAGTCTGGAACCCAGGAGCCCAGCTGGCGGGGGCAGCCCTGATTCCTGCCCTTGTGCCCTCATTCATGTGGCATCTGTACTAAGCAACAGCCCTGCTGTGGACAGAGGGGCAGCACTGGGGATAGGAGGGTGCGGGAGAAAGTGCAAGACTCCAGGTCCAGGCGTTGTGGGGGTGGGGAGAGGTCGAGCTGGGCCGGTCTAATACCAACCCATGGTCAGTGGGTGCCCCTTCCCCATGCCATCTTGCTGAGGGAGGGACTGGATTGTGAGGAGGGTGAGTTAGGCCTGCCTAGGAGATCACTGAGCCTTAGTGTCACCCTCAAACCCCAGTAGCTGGGCTTGCAGGCCCTGGTGCCACCAGCTCCTTGTGTGATGGGGGAGTCACCTTCCCTGAGTGGGCTGGTAGTATCCTGGGTCATCTTGTCCACAG'.upper()\n",
    "\n",
    "full_seq = left_context + intron_exon_intron + right_context\n",
    "\n",
    "exon_seq = 'GCCGTGGCATGCGGGGATGGCCATCACTGCTGCCCACGGGGCTTCCACTGCAGTGCAGACGGGCGATCCTGCTTCCAAAGATCAG'\n",
    "ASO_seq = 'GGAACCCAGGAGCCCAG'\n",
    "\n",
    "\n",
    "acceptor_pos=5115 # full_seq에서 acceptor 위치\n",
    "donor_pos=5199 # (10769 + len(exon_seq)-1), full_seq에서 donor 위치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "center-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AG'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq[acceptor_pos-2:acceptor_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moral-oxide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GT'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq[donor_pos+1:donor_pos+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-armenia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hydraulic-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10676"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-iraqi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-chest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spoken-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_with_seq(seq):\n",
    "    input_x = one_hot_encode(seq)[None, :]\n",
    "    output_y = np.mean([spliceai_models[m].predict(input_x) for m in range(5)], axis=0)\n",
    "    return output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "irish-cornwall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f512011a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "done 100  /  done 120  /  done 140  /  done 160  /  done 180  /  done 200  /  done 220  /  done 240  /  done 260  /  done 280  /  done 300  /  done 320  /  done 340  /  done 360  /  done 380  /  done 400  /  done 420  /  done 440  /  done 460  /  done 480  /  done 500  /  done 520  /  done 540  /  done 560  /  done 580  /  done 600  /  done 620  /  done 640  /  done 660  /  done 680  /  done 700  /  done 720  /  done 740  /  done 760  /  done 780  /  done 800  /  done 820  /  done 840  /  done 860  /  done 880  /  done 900  /  done 920  /  done 940  /  done 960  /  done 980  /  done 1000  /  done 1020  /  done 1040  /  done 1060  /  done 1080  /  done 1100  /  done 1120  /  done 1140  /  done 1160  /  done 1180  /  done 1200  /  done 1220  /  done 1240  /  done 1260  /  done 1280  /  done 1300  /  done 1320  /  done 1340  /  done 1360  /  done 1380  /  done 1400  /  done 1420  /  done 1440  /  done 1460  /  done 1480  /  done 1500  /  done 1520  /  done 1540  /  done 1560  /  done 1580  /  done 1600  /  done 1620  /  done 1640  /  done 1660  /  done 1680  /  done 1700  /  done 1720  /  done 1740  /  done 1760  /  done 1780  /  done 1800  /  done 1820  /  done 1840  /  done 1860  /  done 1880  /  done 1900  /  done 1920  /  done 1940  /  done 1960  /  done 1980  /  done 2000  /  done 2020  /  done 2040  /  done 2060  /  done 2080  /  done 2100  /  done 2120  /  done 2140  /  done 2160  /  done 2180  /  done 2200  /  done 2220  /  done 2240  /  done 2260  /  done 2280  /  done 2300  /  done 2320  /  done 2340  /  done 2360  /  done 2380  /  done 2400  /  done 2420  /  done 2440  /  done 2460  /  done 2480  /  done 2500  /  done 2520  /  done 2540  /  done 2560  /  done 2580  /  done 2600  /  done 2620  /  done 2640  /  done 2660  /  done 2680  /  done 2700  /  done 2720  /  done 2740  /  done 2760  /  done 2780  /  done 2800  /  done 2820  /  done 2840  /  done 2860  /  done 2880  /  done 2900  /  done 2920  /  done 2940  /  done 2960  /  done 2980  /  done 3000  /  done 3020  /  done 3040  /  done 3060  /  done 3080  /  done 3100  /  done 3120  /  done 3140  /  done 3160  /  done 3180  /  done 3200  /  done 3220  /  done 3240  /  done 3260  /  done 3280  /  done 3300  /  done 3320  /  done 3340  /  done 3360  /  done 3380  /  done 3400  /  done 3420  /  done 3440  /  done 3460  /  done 3480  /  done 3500  /  done 3520  /  done 3540  /  done 3560  /  done 3580  /  done 3600  /  done 3620  /  done 3640  /  done 3660  /  done 3680  /  done 3700  /  done 3720  /  done 3740  /  done 3760  /  done 3780  /  done 3800  /  done 3820  /  done 3840  /  done 3860  /  done 3880  /  done 3900  /  done 3920  /  done 3940  /  done 3960  /  done 3980  /  done 4000  /  done 4020  /  done 4040  /  done 4060  /  done 4080  /  done 4100  /  done 4120  /  done 4140  /  done 4160  /  done 4180  /  done 4200  /  done 4220  /  done 4240  /  done 4260  /  done 4280  /  done 4300  /  done 4320  /  done 4340  /  done 4360  /  done 4380  /  done 4400  /  done 4420  /  done 4440  /  done 4460  /  done 4480  /  done 4500  /  done 4520  /  done 4540  /  done 4560  /  done 4580  /  done 4600  /  done 4620  /  done 4640  /  done 4660  /  done 4680  /  done 4700  /  done 4720  /  done 4740  /  done 4760  /  done 4780  /  done 4800  /  done 4820  /  done 4840  /  done 4860  /  done 4880  /  done 4900  /  done 4920  /  done 4940  /  done 4960  /  done 4980  /  done 5000  /  done 5020  /  done 5040  /  done 5060  /  done 5080  /  done 5100  /  done 5120  /  done 5140  /  done 5160  /  done 5180  /  done 5200  /  done 5220  /  done 5240  /  done 5260  /  done 5280  /  done 5300  /  done 5320  /  done 5340  /  done 5360  /  done 5380  /  done 5400  /  done 5420  /  done 5440  /  done 5460  /  done 5480  /  done 5500  /  done 5520  /  done 5540  /  done 5560  /  done 5580  /  done 5600  /  done 5620  /  done 5640  /  done 5660  /  done 5680  /  done 5700  /  done 5720  /  done 5740  /  done 5760  /  done 5780  /  done 5800  /  done 5820  /  done 5840  /  done 5860  /  done 5880  /  done 5900  /  done 5920  /  done 5940  /  done 5960  /  done 5980  /  done 6000  /  done 6020  /  done 6040  /  done 6060  /  done 6080  /  done 6100  /  done 6120  /  done 6140  /  done 6160  /  done 6180  /  done 6200  /  done 6220  /  done 6240  /  done 6260  /  done 6280  /  done 6300  /  done 6320  /  done 6340  /  done 6360  /  done 6380  /  done 6400  /  done 6420  /  done 6440  /  done 6460  /  done 6480  /  done 6500  /  done 6520  /  done 6540  /  done 6560  /  done 6580  /  done 6600  /  done 6620  /  done 6640  /  done 6660  /  done 6680  /  done 6700  /  done 6720  /  done 6740  /  done 6760  /  done 6780  /  done 6800  /  done 6820  /  done 6840  /  done 6860  /  done 6880  /  done 6900  /  done 6920  /  done 6940  /  done 6960  /  done 6980  /  done 7000  /  done 7020  /  done 7040  /  done 7060  /  done 7080  /  done 7100  /  done 7120  /  done 7140  /  done 7160  /  done 7180  /  done 7200  /  done 7220  /  done 7240  /  done 7260  /  done 7280  /  done 7300  /  done 7320  /  done 7340  /  done 7360  /  done 7380  /  done 7400  /  done 7420  /  done 7440  /  done 7460  /  done 7480  /  done 7500  /  done 7520  /  done 7540  /  done 7560  /  done 7580  /  done 7600  /  done 7620  /  done 7640  /  done 7660  /  done 7680  /  done 7700  /  done 7720  /  done 7740  /  done 7760  /  done 7780  /  done 7800  /  done 7820  /  done 7840  /  done 7860  /  done 7880  /  done 7900  /  done 7920  /  done 7940  /  done 7960  /  done 7980  /  done 8000  /  done 8020  /  done 8040  /  done 8060  /  done 8080  /  done 8100  /  done 8120  /  done 8140  /  done 8160  /  done 8180  /  done 8200  /  done 8220  /  done 8240  /  done 8260  /  done 8280  /  done 8300  /  done 8320  /  done 8340  /  done 8360  /  done 8380  /  done 8400  /  done 8420  /  done 8440  /  done 8460  /  done 8480  /  done 8500  /  done 8520  /  done 8540  /  done 8560  /  done 8580  /  done 8600  /  done 8620  /  done 8640  /  done 8660  /  done 8680  /  done 8700  /  done 8720  /  done 8740  /  done 8760  /  done 8780  /  done 8800  /  done 8820  /  done 8840  /  done 8860  /  done 8880  /  done 8900  /  done 8920  /  done 8940  /  done 8960  /  done 8980  /  done 9000  /  done 9020  /  done 9040  /  done 9060  /  done 9080  /  done 9100  /  done 9120  /  done 9140  /  done 9160  /  done 9180  /  done 9200  /  done 9220  /  done 9240  /  done 9260  /  done 9280  /  done 9300  /  done 9320  /  done 9340  /  done 9360  /  done 9380  /  done 9400  /  done 9420  /  done 9440  /  done 9460  /  done 9480  /  done 9500  /  done 9520  /  done 9540  /  done 9560  /  done 9580  /  done 9600  /  done 9620  /  done 9640  /  done 9660  /  done 9680  /  done 9700  /  done 9720  /  done 9740  /  done 9760  /  done 9780  /  done 9800  /  done 9820  /  done 9840  /  done 9860  /  done 9880  /  done 9900  /  done 9920  /  done 9940  /  done 9960  /  done 9980  /  done 10000  /  done 10020  /  done 10040  /  done 10060  /  done 10080  /  done 10100  /  done 10120  /  done 10140  /  done 10160  /  done 10180  /  done 10200  /  "
     ]
    }
   ],
   "source": [
    "\n",
    "all_result=[]\n",
    "\n",
    "input_seq=full_seq\n",
    "len_of_aso=17\n",
    "\n",
    "\n",
    "mask_seq='N'*17\n",
    "\n",
    "best_total=0.0\n",
    "\n",
    "for now_mut_pos in range(acceptor_pos-5030,donor_pos+5020):\n",
    "    \n",
    "    original_seq = input_seq\n",
    "    masked_seq = input_seq[:now_mut_pos] + mask_seq + input_seq[now_mut_pos+len_of_aso:]\n",
    "\n",
    "\n",
    "    original_donor_seq = original_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    original_acceptor_seq = original_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    masked_donor_seq = masked_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "    masked_acceptor_seq = masked_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "\n",
    "\n",
    "    original_donor_prob = get_prob_with_seq(original_donor_seq)[0][0][2]\n",
    "    original_acceptor_prob = get_prob_with_seq(original_acceptor_seq)[0][0][1]\n",
    "\n",
    "    masked_donor_prob = get_prob_with_seq(masked_donor_seq)[0][0][2]\n",
    "    masked_acceptor_prob = get_prob_with_seq(masked_acceptor_seq)[0][0][1]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    result_total = (masked_donor_prob+masked_acceptor_prob)/2.0\n",
    "    delta_acceptor = masked_acceptor_prob - original_acceptor_prob\n",
    "    delta_donor = masked_donor_prob - original_donor_prob\n",
    "    delta_total = delta_acceptor + delta_donor\n",
    "    delta_pos = now_mut_pos\n",
    "    erased_seq = input_seq[now_mut_pos:now_mut_pos+17]\n",
    "\n",
    "    all_result.append( [delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq] )\n",
    "        \n",
    "        \n",
    "    f = open(\"ASO_grn_result_renew.txt\", 'a')\n",
    "    \n",
    "    def inline_str(str_list):\n",
    "        num = len(str_list)\n",
    "        ret=\"\"\n",
    "        for i in range(num):\n",
    "            ret+=str(str_list[i])\n",
    "            if i<num-1:\n",
    "                ret+='\\t'\n",
    "        ret+='\\n'\n",
    "        return ret\n",
    "        \n",
    "    \n",
    "    f.write(inline_str([result_total,delta_acceptor,delta_donor,delta_total,delta_pos,erased_seq,original_acceptor_prob,original_donor_prob,masked_acceptor_prob,masked_donor_prob]))\n",
    "    f.close()\n",
    "    \n",
    "    if now_mut_pos%20==0:\n",
    "        print('done '+str(now_mut_pos),end=\"  /  \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-device",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-variable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-fancy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-eugene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-illinois",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-missile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-texture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stable-correspondence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6251"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seq)-len_of_aso+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "every-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"ASO_result.txt\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sustained-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "\n",
    "\n",
    "for line in f:\n",
    "    p=line.split('\\t')\n",
    "    res.append([float(p[0]),p[4],int(p[3])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sonic-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.28564858, 'CCAGCATTATGAAAGTG', 5832],\n",
       " [0.2863837, 'TTAGACAAAATCAAAAA', 5773],\n",
       " [0.28948206, 'GTGCTCACATTCCTTAA', 5798],\n",
       " [0.2931587, 'TGCCAGCATTATGAAAG', 5830],\n",
       " [0.3000751, 'TTTTAGACAAAATCAAA', 5771],\n",
       " [0.30198628, 'GTTTTAGACAAAATCAA', 5770],\n",
       " [0.3060084, 'CATTCCTTAAATTAAGG', 5805],\n",
       " [0.30910528, 'CTGCCAGCATTATGAAA', 5829],\n",
       " [0.31307673, 'ACATTCCTTAAATTAAG', 5804],\n",
       " [0.3230291, 'ATTCCTTAAATTAAGGA', 5806]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort()\n",
    "res[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-nerve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-objective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-arlington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-harmony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-audit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-tonight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "treated-shepherd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "portable-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mutation(input_seq, donor_pos, acceptor_pos, len_of_aso ,use_n_as_aso=True):\n",
    "    \n",
    "#     total_delta=0.8\n",
    "#     acceptor_delta=0.5\n",
    "#     donor_delta=0.3\n",
    "#     delta_pos=536\n",
    "#     erased_seq='ATTTGGCCAAGCGATGC'\n",
    "    \n",
    "    \n",
    "#     all_result.append([[total_delta,acceptor_delta,donor_delta,delta_pos,erased_seq]])\n",
    "    \n",
    "    \n",
    "    all_result=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if use_n_as_aso:\n",
    "        mask_seq='N'*len_of_aso\n",
    "    else:\n",
    "        mask_seq=make_random_seq(len_of_aso)\n",
    "    \n",
    "    best_total=0.0\n",
    "    \n",
    "    for now_mut_pos in range(len(input_seq)-len_of_aso+1):\n",
    "        original_seq = input_seq\n",
    "        masked_seq = input_seq[:now_mut_pos] + mask_seq + input_seq[now_mut_pos+len_of_aso:]\n",
    "        \n",
    "        original_seq = left_context + original_seq + right_context\n",
    "        masked_seq = left_context + masked_seq + right_context\n",
    "        \n",
    "        \n",
    "        original_donor_seq = original_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "        original_acceptor_seq = original_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "        \n",
    "        \n",
    "        masked_donor_seq = masked_seq[donor_pos-5000:donor_pos+5000+1]\n",
    "        masked_acceptor_seq = masked_seq[acceptor_pos-5000:acceptor_pos+5000+1]\n",
    "        \n",
    "\n",
    "        original_donor_prob = get_prob_with_seq(original_donor_seq)[0][0][2]\n",
    "        original_acceptor_prob = get_prob_with_seq(original_acceptor_seq)[0][0][1]\n",
    "        \n",
    "        masked_donor_prob = get_prob_with_seq(masked_donor_seq)[0][0][2]\n",
    "        masked_acceptor_prob = get_prob_with_seq(masked_acceptor_seq)[0][0][1]\n",
    "        \n",
    "        \n",
    "        delta_acceptor = masked_acceptor_prob - original_acceptor_prob\n",
    "        delta_donor = masked_donor_prob - original_donor_prob\n",
    "        delta_total = delta_acceptor + delta_donor\n",
    "        delta_pos = now_mut_pos\n",
    "        erased_seq = input_seq[now_mut_pos:now_mut_pos+17]\n",
    "        \n",
    "        all_result.append( [delta_total,delta_acceptor,delta_donor,delta_pos,erased_seq] )\n",
    "      \n",
    "        best_total = max(best_total,delta_total)\n",
    "    \n",
    "        if now_mut_pos%20==0:\n",
    "            print('done '+str(now_mut_pos),end=\"  /  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0  /  done 10  /  done 20  /  done 30  /  done 40  /  done 50  /  done 60  /  done 70  /  done 80  /  done 90  /  done 100  /  done 110  /  done 120  /  done 130  /  done 140  /  done 150  /  done 160  /  done 170  /  done 180  /  done 190  /  done 200  /  done 210  /  done 220  /  done 230  /  done 240  /  done 250  /  done 260  /  done 270  /  done 280  /  done 290  /  done 300  /  done 310  /  done 320  /  done 330  /  done 340  /  done 350  /  done 360  /  done 370  /  done 380  /  done 390  /  done 400  /  done 410  /  done 420  /  done 430  /  done 440  /  done 450  /  done 460  /  done 470  /  done 480  /  done 490  /  done 500  /  done 510  /  done 520  /  done 530  /  done 540  /  done 550  /  done 560  /  done 570  /  done 580  /  done 590  /  done 600  /  done 610  /  done 620  /  done 630  /  done 640  /  done 650  /  done 660  /  done 670  /  done 680  /  done 690  /  done 700  /  done 710  /  done 720  /  done 730  /  done 740  /  done 750  /  done 760  /  done 770  /  done 780  /  done 790  /  done 800  /  done 810  /  done 820  /  done 830  /  "
     ]
    }
   ],
   "source": [
    "predict_mutation(intron_exon_intron,donor_pos,acceptor_pos,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-trustee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "5초에 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-transcription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-triangle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-prize",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-governor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mutation(intron_exon_intron,donor_pos,acceptor_pos,17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spliceai",
   "language": "python",
   "name": "spliceai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
